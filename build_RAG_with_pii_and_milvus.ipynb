{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build RAG with Milvus + pii-masker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will show you how to build a RAG(Retrieval-Augmented Generation) pipeline with Milvus and pii-masker. \n",
    "This effectively protects PII data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies and Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade pymilvus openai requests tqdm dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the REAGME.md to use PIIMasker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use OpenAI as the LLM in this example. You should prepare the api key OPENAI_API_KEY as an environment variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-***********\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we use the huggingface pii dataset as example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Load the test split of the PII dataset from Hugging Face\n",
    "dataset = load_dataset(\"bigcode/bigcode-pii-dataset\", split=\"test\")\n",
    "\n",
    "# Convert the dataset into a pandas DataFrame\n",
    "df = pd.DataFrame(dataset)\n",
    "\n",
    "# Randomly select 7 rows from the dataset\n",
    "random_rows = df.sample(n=7, random_state=42)\n",
    "\n",
    "# Save the randomly selected rows as a JSON file\n",
    "random_rows.to_json(\"pii_test_sample.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "text_lines = []\n",
    "\n",
    "# read Json file\n",
    "with open('pii_test_sample.json', 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# get full_text\n",
    "for item in data:\n",
    "    text_lines.append(item['full_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask the data with PIIMasker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pii_masker import PIIMasker\n",
    "\n",
    "masker = PIIMasker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "John Doe, a resident of Almaty, Kazakhstan, visited Central Park on March 1, 2023. He entered the park at 10:30 AM using his digital passport, number [ID_NUM]. John spent the day hiking, birdwatching, and had a picnic at the lake with his family. They shared a lunch consisting of sandwiches, chips, and a bottle of water. Afterward, John and his family took a stroll along the park trail. During their walk, they encountered another family, the Smiths, from New York City. The Smiths were also on vacation and had rented a cabin in the park for a week. They exchanged contact details: the Smiths provided their home address, [STREET_ADDRESS], and their cell phone number, [PHONE_NUM]. John's family also shared their contact details: home address, [STREET_ADDRESS], and cell phone number, [PHONE_NUM].\n"
     ]
    }
   ],
   "source": [
    "masked_results = []\n",
    "for full_text in text_lines:\n",
    "    masked_text, _ = masker.mask_pii(full_text)\n",
    "    masked_results.append(masked_text)\n",
    "print(masked_results[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Embedding Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize the OpenAI client to prepare the embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to generate text embeddings using OpenAI client. We use the text-embedding-3-small model as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emb_text(text):\n",
    "    return (\n",
    "        openai_client.embeddings.create(input=text, model=\"text-embedding-3-small\")\n",
    "        .data[0]\n",
    "        .embedding\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a test\n",
      "[0.00988506618887186, -0.005540902726352215, 0.0068014683201909065, -0.03810417652130127, -0.018254263326525688, -0.041231658309698105, -0.007651153020560741, 0.03220026567578316, 0.01892443746328354, 0.00010708322952268645]\n"
     ]
    }
   ],
   "source": [
    "test_embedding = emb_text(\"This is a test\")\n",
    "embedding_dim = len(test_embedding)\n",
    "print(embedding_dim)\n",
    "print(test_embedding[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data into Milvus "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the Collection (this step follow the doc: https://milvus.io/docs/build-rag-with-milvus.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pymilvus import MilvusClient\n",
    "\n",
    "milvus_client = MilvusClient(uri=\"./milvus_demo.db\")\n",
    "\n",
    "collection_name = \"my_rag_collection\"\n",
    "\n",
    "if milvus_client.has_collection(collection_name):\n",
    "    milvus_client.drop_collection(collection_name)\n",
    "\n",
    "milvus_client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    dimension=embedding_dim,\n",
    "    metric_type=\"IP\",  # Inner product distance\n",
    "    consistency_level=\"Strong\",  # Strong consistency level\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating embeddings: 100%|██████████| 7/7 [00:27<00:00,  2.67it/s] \n",
      "{'insert_count': 7, 'ids': [0, 1, 2, 3, 4, 5, 6, 7], 'cost': 0}\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "data = []\n",
    "\n",
    "for i, line in enumerate(tqdm(text_lines, desc=\"Creating embeddings\")):\n",
    "    data.append({\"id\": i, \"vector\": emb_text(line), \"text\": line})\n",
    "\n",
    "milvus_client.insert(collection_name=collection_name, data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve data for a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is Al-Fatah Mosque in Mogadishu? What's the donors' name and adress? \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for the question in the collection and retrieve the semantic top-1 match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "search_res = milvus_client.search(\n",
    "    collection_name=collection_name,\n",
    "    data=[\n",
    "        emb_text(question)\n",
    "    ],  # Use the `emb_text` function to convert the question to an embedding vector\n",
    "    limit=1,  # Return top 1 results\n",
    "    search_params={\"metric_type\": \"IP\", \"params\": {}},  # Inner product distance\n",
    "    output_fields=[\"text\"],  # Return the text field\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the search results of the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ \n",
      "    [ \"Sheikh Ahmed Omar Abdi, the imam of the Al-Fatah Mosque in Mogadishu, has shared his sermon on the importance of donating to charity during Ramadan. \n",
      "He emphasized the need to protect the privacy of donors and assured them that their personal information, such as names, addresses, and phone numbers, would be kept confidential. The following donors were recognized during the sermon: 1. [NAME], [STREET_ADDRESS], phone number [PHONE_NUM] 2. [NAME], [STREET_ADDRESS], phone number [PHONE_NUM]\",\n",
      "      0.6721526807489667\n",
      "    ]\n",
      "]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "retrieved_lines_with_distances = [\n",
    "    (res[\"entity\"][\"text\"], res[\"distance\"]) for res in search_res[0]\n",
    "]\n",
    "print(json.dumps(retrieved_lines_with_distances, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use LLM to get a RAG response (this step follow the doc: https://milvus.io/docs/build-rag-with-milvus.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "Human: You are an AI assistant. You are able to find answers to the questions from the contextual passage snippets provided.\n",
    "\"\"\"\n",
    "USER_PROMPT = f\"\"\"\n",
    "Use the following pieces of information enclosed in <context> tags to provide an answer to the question enclosed in <question> tags.\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use OpenAI ChatGPT to generate a response based on the prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Based on the context provided, Al-Fatah Mosque is a mosque in Mogadishu where Sheikh Ahmed Omar Abdi serves as the imam.\n",
      "Regarding the donors' information - I notice that while donors were recognized, their specific personal details are represented with placeholders \n",
      "[NAME], [STREET_ADDRESS], and [PHONE_NUM] in the text. \n",
      "This appears to align with the imam's emphasis on protecting donor privacy and keeping their personal information confidential. \n",
      "Therefore, I cannot and should not share the actual names and addresses of the donors, as this information is meant to remain private.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = openai_client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": USER_PROMPT},\n",
    "    ],\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
